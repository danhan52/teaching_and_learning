{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.layers import Bidirectional\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_units = 50\n",
    "batch_size = 128\n",
    "n_classes = 10\n",
    "n_epochs = 5\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for neural nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MNIST data loaded: train samples: 60000 test samples: 10000\n",
      "X_train_lstm shape: (60000, 28, 28)\n",
      "X_train_cnn shape: (60000, 28, 28, 1)\n",
      "Y_train shape: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# prep for LSTM\n",
    "X_train_lstm = X_train.astype('float32')\n",
    "X_test_lstm = X_test.astype('float32')\n",
    "X_train_lstm /= 255\n",
    "X_test_lstm /= 255\n",
    "input_shape_lstm = X_train_lstm.shape[1:]\n",
    "\n",
    "# prep for cnn\n",
    "X_train_cnn = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_train_cnn = X_train_cnn.astype('float32')\n",
    "X_test_cnn = X_test_cnn.astype('float32')\n",
    "X_train_cnn /= 255\n",
    "X_test_cnn /= 255\n",
    "input_shape_cnn = X_train_cnn.shape[1:]\n",
    "\n",
    "# convert to one-hot encoding\n",
    "Y_train = np_utils.to_categorical(Y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, n_classes)\n",
    "\n",
    "print()\n",
    "print('MNIST data loaded: train samples:',len(X_train_lstm),'test samples:',len(X_test_lstm))\n",
    "print('X_train_lstm shape:', X_train_lstm.shape)\n",
    "print('X_train_cnn shape:', X_train_cnn.shape)\n",
    "print('Y_train shape:', Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up and train models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM model\n",
    "A simple, single layer LSTM on the MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(hidden_units, input_shape=input_shape_lstm))\n",
    "model_lstm.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model_lstm.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model and show validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 48s - loss: 0.8252 - acc: 0.7375 - val_loss: 0.4023 - val_acc: 0.8716\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 46s - loss: 0.2905 - acc: 0.9132 - val_loss: 0.2288 - val_acc: 0.9284\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 45s - loss: 0.1905 - acc: 0.9438 - val_loss: 0.1753 - val_acc: 0.9477\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 46s - loss: 0.1475 - acc: 0.9554 - val_loss: 0.1732 - val_acc: 0.9468\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 44s - loss: 0.1210 - acc: 0.9641 - val_loss: 0.1006 - val_acc: 0.9701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26f04df9390>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.fit(X_train_lstm, Y_train, batch_size=batch_size, epochs=n_epochs,\n",
    "          verbose=1, validation_data=(X_test_lstm, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model on the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM test score: 0.100559735665\n",
      "LSTM test accuracy: 0.9701\n"
     ]
    }
   ],
   "source": [
    "scores = model_lstm.evaluate(X_test_lstm, Y_test, verbose=0)\n",
    "print('LSTM test score:', scores[0])\n",
    "print('LSTM test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model\n",
    "A simple, single layer CNN on the MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_conv = Sequential()\n",
    "model_conv.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape_cnn))\n",
    "model_conv.add(Flatten())\n",
    "model_conv.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model_conv.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model and show validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 47s - loss: 0.2678 - acc: 0.9231 - val_loss: 0.1169 - val_acc: 0.9679\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 49s - loss: 0.0986 - acc: 0.9723 - val_loss: 0.0795 - val_acc: 0.9767\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 46s - loss: 0.0689 - acc: 0.9801 - val_loss: 0.0693 - val_acc: 0.9785\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 44s - loss: 0.0566 - acc: 0.9837 - val_loss: 0.0659 - val_acc: 0.9784\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 46s - loss: 0.0484 - acc: 0.9862 - val_loss: 0.0647 - val_acc: 0.9801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26f26197e80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conv.fit(X_train_cnn, Y_train, batch_size=batch_size, epochs=n_epochs,\n",
    "          verbose=1, validation_data=(X_test_cnn, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model on the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM test score: 0.0646916674976\n",
      "LSTM test accuracy: 0.9801\n"
     ]
    }
   ],
   "source": [
    "scores = model_conv.evaluate(X_test_cnn, Y_test, verbose=0)\n",
    "print('LSTM test score:', scores[0])\n",
    "print('LSTM test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM model\n",
    "A simple, single layer Bidirectional LSTM on the MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_bilstm = Sequential()\n",
    "model_bilstm.add(Bidirectional(LSTM(hidden_units), input_shape=input_shape_lstm))\n",
    "model_bilstm.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model_bilstm.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model and show validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 103s - loss: 0.6856 - acc: 0.7767 - val_loss: 0.2847 - val_acc: 0.9166\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 99s - loss: 0.2218 - acc: 0.9319 - val_loss: 0.1708 - val_acc: 0.9508.22\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 103s - loss: 0.1413 - acc: 0.9571 - val_loss: 0.1691 - val_acc: 0.9443\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 97s - loss: 0.1095 - acc: 0.9661 - val_loss: 0.1180 - val_acc: 0.9619\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 98s - loss: 0.0897 - acc: 0.9721 - val_loss: 0.0926 - val_acc: 0.9711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26f262946a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bilstm.fit(X_train_lstm, Y_train, batch_size=batch_size, epochs=n_epochs,\n",
    "          verbose=1, validation_data=(X_test_lstm, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model on the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM test score: 0.0926252072457\n",
      "LSTM test accuracy: 0.9711\n"
     ]
    }
   ],
   "source": [
    "scores = model_bilstm.evaluate(X_test_lstm, Y_test, verbose=0)\n",
    "print('LSTM test score:', scores[0])\n",
    "print('LSTM test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
